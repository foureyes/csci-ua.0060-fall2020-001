---
layout: homework
title: "Assignment #2"
---
<style>
.hl {
	background-color: yellow;
}
img {
    border: 1px solid #000;
}

.warning {
    background-color: yellow;
    color: #aa1122;
    font-weight: bold;
}

.hidden {
    display: none;
}

.hintButton {
    color: #7788ff;
    cursor: pointer;
}
</style>
<script>
document.addEventListener('DOMContentLoaded', hideHints);

function hideHints(evt) {
    document.querySelectorAll('.hint').forEach((ele, i) => {
        const div = document.createElement('div');
        div.id = 'hint' + i + 'Button';
        ele.id = 'hint' + i;
        ele.classList.add('hidden');
        div.addEventListener('click', onClick);
        div.textContent = 'Show Hint';
        div.className = 'hintButton';
        ele.parentNode.insertBefore(div, ele);
    });

}

function onClick(evt) {
    const hintId = this.id.replace('Button', '');
    const hint = document.getElementById(hintId);
    hint.classList.toggle('hidden');
    this.textContent = this.textConent === 'Show Hint' ? 'Hide Hint' : 'Show Hint';
}
</script>

# Assignment #2 - Sourcing and Cleaning Data - Due Tue, September 29th at 11pm

Clone the homework #2 repository when it is created for you.

## Goals

* find a data set to work with
* write documentation
* use Python to read and transform the data

## Requirements

* 1 x documentation:
	* `README.md`
* 1 x python program:
	* `src/homework02.py`
* 1 x original data set:
	* `data/raw/*`
	* ‚ö†Ô∏è include in repository if possible
	* otherwise, link to data set if file size &gt; 100MB

## Overview

In this assignment, you'll find a data source, write documentation and create a single python program. There are 5 parts to this assignment (details in the following sections __Part 1 - 5__; the steps below are just an overview):

1. write some questions that _may_ be answered by using summary statistics on numeric columns or some rudimentary analysis on text columns in a data set
2. select and document a data set
	* ‚ö†Ô∏è the data should be comma / pipe / tab delimited, json, or fixed width
	* ‚ö†Ô∏è the data set should have __two numeric columns__
	* include documentation regarding the source of the data
	* include the data set in your repository so that your code can be run by the graders without having to perform any setup (if data set is &gt; 100MB, link to file instead)
3. calculate summary statistics on both columns using regular python (if this is not possible, you can foll back on analysis on text columns, such as counts)
4. validate calculations using a spreadsheet (such as LibreOffice, Google Sheets, Excel, etc.)
5. write a conclusion answering your questions in part 1 based on the results in parts 2, 3,  and 4
	* describe the results of your calculations 
	* describe whether or not they were able to answer your questions from part 1

## Part 1 - Questions


Write some questions (minimally 2) that you think can be answered by finding the _right_ data set. üëÄ See Vicky Steeves' slides on finding data -- [the slide titled "Steps to finding the \*right\* data"](https://tinyurl.com/find-data) -- to help construct your questions.

Focus on questions that _may_ be answered by using summary statistics on numeric columns in a data set. Alternatively, you can use rudimentary analysis on text-based columns that have a predefined set of possible values, such as counts / frequency.

‚ö†Ô∏è __If you have trouble thinking of research topics / questions, you can do parts 1 and 2 in reverse order__ ... by finding an interesting data set first, and then formulating questions afterwards.

Write your questions ... along with _where_ you think you'll find answers within the `README.md` file using the following template, with the parts marked TODO to be filled in:

```
# Homework 02

## Questions

### Question 1: 

TODO (write the question)

* Who (population): TODO
* What (subject, discipline): TODO
* Where (location): TODO
* When (snapshot, longitudinal): TODO
* How much data do you need to do the analysis/work: TODO

### Question N: 

TODO (write the question)

* Who (population): TODO
* What (subject, discipline): TODO
* Where (location): TODO
* When (snapshot, longitudinal): TODO
* How much data do you need to do the analysis/work: TODO

### Who Might Collect Relevant Data / What Articles or Publications Cite a Relevant Data Set?

TODO (answer question here)
```


## Part 2 - Selecting a Data Set, Adding Documentation


#### Find a data set that you'd like to work with

Find a data set that you're interested in... that's publicly available online as a text file (csv, for example). Download your data from a source that has some information regarding the provenance of the data (_where did it come from!?_). 


üëÄ See Vicky Steeves' slides on finding data -- specifically, start with the [Some good general data sources to start] slide (https://tinyurl.com/find-data) -- to help in your search for a data set

Some guidelines:

1. do not use data sets that we've worked on or discussed in class ([fortune.com's global 500](https://fortune.com/global500/2019/search/?sector=Technology) and [GISS Surface Temperature Analysis](https://data.giss.nasa.gov/gistemp/)), because, uh... we probably already wrote (or will write) some code for it üôÉ
2. <span class="hl">write code that's different from  - or builds significantly on - the programs that we've done in class</span> (it's not adequate to simply use class sample code with a different data set üôÖ)

#### Write some documentation 

1. In the file `README.md` (you can use any text editor to open this file)...
2. Use the markdown below as a template to cite the data source and describe the data set
3. Fill in the parts marked as "TODO"


```
## About the Data

1. Name / Title: (TODO: name of data set)
2. Link to Data: (TODO: link to any documentation about the data that you've found )
3. Source / Origin: 
	* Author or Creator: TODO
	* Publication Date: TODO
	* Publisher: TODO
	* Version or Data Accessed: TODO
4. License: (TODO: name of license)
5. Can You Use this Data Set for Your Intended Use Case? (TODO: answer this question)
```


#### Show Some Data and Document its Format

Document the format of the data set in your `README.md` file using the template below:

```
## Format

### Overview

Format: (TODO: add what file format the data is in)
Size: (TODO: how large is the file in KB, MB, GB, etc. ... use finder, windows explorer for this)
Number of Records: (TODO: how many rows; in the case of JSON, how many objects?)

### Sample of Data

(TODO show a few lines of data from the actual file by simple copy and paste) 

### Fields or Column Headers

* Field/Column 1: (TODO add field name and potential type using Python types)
* Field/Column 2: (TODO same as above)
* Field/Column N: (TODO same as above)
```


## Part 3 - Descriptive Statistics

1. in `src/homework02.py`, read the data from at least two columns of your file; try to read the numeric data 
	* you can read the individual columns into separate lists, dictionaries, tuples, etc.
	* ...or you can read all of the data as a multidimensional list
	* you'll have to parse the data into a numeric type 
	* you may have to clean up the data before it can be converted into a numeric type... for example: 
		* removing leading / trailing whitespace
		* replacing commas 
		* removing dollar signs
		* deal with missing data
		* etc.
	* use the following code to construct absolute paths for the file to open
		```
	import os
    path = os.path.dirname(os.path.abspath(__file__))
    full_path_in = os.path.join(path, 'name_of_file.txt')
```	
2. calculate the following descriptive statistics on these two columns
	1. examine outliers with min and/or max
	2. measure central tendency by calculating any of the following:
		* mean
		* median 
		* mode
	3. measure dispersion with any of the following
		* variance
		* standard deviation 
		* range
	4. if you're using a text column, you can run calculations such as frequency, unique values, etc. (try to use at least one numeric column, though... even if it's not relevant for your question0
3. output the results using print
4. add the results to your markdown file

```
## Analysis

### Central Tendency

TODO: copy and paste your results here

### Dispersion

TODO: copy and paste your results here

### Outliers

TODO: are there any potential outliers?

### Other

TODO: copy and paste your results here
```

## Part 4 - Validation

* try opening your original file with LibreOffice, Google Sheets, etc. 
* using your spreadsheet's functions, confirm that your summary statistics match
* in a markdown cell in your notebook:
	* compare and contrast the results from you calculations with python... to the results from your spreadsheet
	* investigate any discrepancies, and - if possible - describe (or hypothesize) why there are differences 


## Part 5 - Conclusion

Write a conclusion answering your questions in part 2 based on the results in parts 2 and 3

* describe the results of your calculations 
* describe whether or not they were able to answer your questions from part 1

```
## Conclusion

TODO: write your conclusion here (interpret results of calculations; does it help answer your original questions?)
```
