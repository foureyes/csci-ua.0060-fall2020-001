---
layout: homework
title: "Assignment #7"
---
<style>
.hl {
	background-color: yellow;
}
img {
    border: 1px solid #000;
}

.warning {
    background-color: yellow;
    color: #aa1122;
    font-weight: bold;
}

.hidden {
    display: none;
}

.hintButton {
    color: #7788ff;
    cursor: pointer;
}
</style>
<script>
document.addEventListener('DOMContentLoaded', hideHints);

function hideHints(evt) {
    document.querySelectorAll('.hint').forEach((ele, i) => {
        const div = document.createElement('div');
        div.id = 'hint' + i + 'Button';
        ele.id = 'hint' + i;
        ele.classList.add('hidden');
        div.addEventListener('click', onClick);
        div.textContent = 'Show Hint';
        div.className = 'hintButton';
        ele.parentNode.insertBefore(div, ele);
    });

}

function onClick(evt) {
    const hintId = this.id.replace('Button', '');
    const hint = document.getElementById(hintId);
    hint.classList.toggle('hidden');
    this.textContent = this.textConent === 'Show Hint' ? 'Hide Hint' : 'Show Hint';
}
</script>

# Assignment #7 - Screen Scrape, Database Imports, Using an API / Data Visualization - Due Thursday, Nov 19th at 11pm

In this homework, you'll:

1. "Screen scrape" data from a web site
	* Use `urllib` and `BeautifulSoup` to download and parse html
	* Use `pymysql` to insert data into a database
2. Use an API and Create a Simple Data Visualization

## Part 1 - Load Fall 2020 / Spring 2021 Course into a Database


### Prep

In this part of the assignment, you'll: 


1. Create a data model that holds course data 
2. Programmatically retrieve course data as html pages
3. Extract data from the html retrieved
4. Load the data into a database and run queries

1 - 3 can be done on your computer, but 4 must be done on i6.


### Instructions

#### 1. Create a Data Model


1. Look through the [Fall 2020 CS course schedule](https://cs.nyu.edu/dynamic/courses/schedule/?semester=fall_2020) and [Spring 2021 CS course schedule](https://cs.nyu.edu/dynamic/courses/schedule/?semester=spring_2021) 
2. Create a table or tables to hold the data. You can create a simple single table data model with straightforward columns, or you can create a normalized multi-table model with a non-trivial column mapping. Your discretion! 
	* If you're looking for a challenge, try to figure out how to model so that you can query against meeting times (show me all the classes that meet in the morning or all of the classes that only meet once a week)
	* You're free to extract data that isn't apparent based on the HTML table's columns (for example, graduate or undergraduate isn't a column, but it can be inferred)
3. Add your SQL to create a table or tables in `src/create.sql`
	* You do not have to submit an ER diagram
	* ...Though you can use MySQL Workbench to generate generate `CREATE` statements for you

#### 2. Download Data

In  `src/load_courses.py`:

1. Use `urllib` to download the html pages containing course info for the 2020/2021 academic year (fall 2020 and spring 2021)
2. [Check out the slides for a quick guide on using `urllib`](../slides/web/apis.html#4)
3. Find a way to __print out the contents of each course info page__ (this should just be html)


#### 3. Extract Data

In  `src/load_courses.py`:

1. Install `beautifulsoup4` in your environment 
	* `pip3 install beautifulsoup4` or `sudo pip3 install beautifulsoup4` in terminal / `cmd.exe`
	* if you're using Anaconda [follow the docs for installing modules](https://docs.anaconda.com/anaconda/navigator/tutorials/manage-packages/#installing-a-package)
	* if you're using PyCharm [follow the docs for installing modules](https://www.jetbrains.com/help/pycharm/installing-uninstalling-and-upgrading-packages.html)
2. Modify your `load_courses.py` script:
	* parse and extract data from the html pages retrieved by `urllib`
	* use [`beatifulsoup4`](../slides/web/data-formats-web.html) and optionally, the [`re` (regular expressions) module](http://localhost:7000/slides/py/regex.html), to do this
	* the data extracted should be what you'll use to load into your database
	* now, __instead of printing the content of both pages (from the previous part) as the original html__ 
		* print out the extracted data 
		* for example, show the course number, title, instructor and meeting times

#### 4. Load Data into a Database

In this part, you'll have to login to i6

1. Upload your `load_courses.py` file and `create.sql` file to `i6` (use scp from previous assignments to do this, or use an sftp client if you've used one before)
2. Make sure to install any modules necessary on i6:
	* `pip3 install beautifulsoup4`
	* `pip3 install pymysql`
	* (if you're accustomed to having dependencies listed in in a single file,  that you can also list these files in `requirements.txt` by running `pip3 freeze > requirements.txt` on your computer)
